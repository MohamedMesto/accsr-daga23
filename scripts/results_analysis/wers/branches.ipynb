{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = \"../../../logs/de/asr/evaluate\"\n",
    "folders = {\n",
    "    \"Fine-tuned\": \"version_4\",\n",
    "    \"b3\": \"version_10\",\n",
    "    \"b7\": \"version_11\",\n",
    "    \"b11\": \"version_12\",\n",
    "    \"b15\": \"version_13\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which accent is standard, which are seen and which are unseen\n",
    "classes = {\n",
    "    \"standard\": [\"de\"],\n",
    "    \"seen\": [\"ch\", \"at\"],\n",
    "    \"unseen\": [\"gb\", \"it\", \"de_al\", \"fr\", \"de_ni\", \"us\", \"ca\", \"ru\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load WERs of each file, for each accent\n",
    "wers = dict()\n",
    "for exp, folder in folders.items():\n",
    "    wers[exp] = {k[5:-4]: v for k, v in json.load(open(f\"{exp_dir}/{folder}/avg_wers.json\")).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dictionary into a numpy array, where one axis represents the accents and another the experiments\n",
    "experiments = list(wers.keys())\n",
    "accents = list(wers[experiments[0]].keys())\n",
    "n_words = np.array([wers[experiments[0]][acc][\"n_words\"] for acc in accents])\n",
    "avg_wers = np.array([[wers[exp][acc][\"avg_wer\"] for exp in experiments] for acc in accents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute means for each class, for each experiment\n",
    "class_indices = {k: [accents.index(acc) for acc in v] for k, v in classes.items()}\n",
    "class_means = {k: np.mean(avg_wers[indices], axis=0) for k, indices in class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accent / Dialect | Fine-tuned | b3 | b7 | b11 | b15\n",
      "|---:|---:|---:|---:|---:|---:|\n",
      "at | 1.80 | 1.61 | 1.64 | 1.57 | 1.60\n",
      "gb | 4.11 | 4.03 | 4.44 | 4.03 | 4.03\n",
      "it | 1.40 | 1.34 | 1.33 | 1.29 | 1.30\n",
      "de_al | 1.16 | 1.05 | 1.16 | 1.07 | 1.14\n",
      "fr | 2.68 | 2.32 | 2.29 | 2.28 | 2.32\n",
      "de_ni | 4.31 | 4.27 | 4.17 | 4.09 | 4.08\n",
      "ch | 3.11 | 2.76 | 2.78 | 2.71 | 2.74\n",
      "de | 1.92 | 1.73 | 1.72 | 1.72 | 1.73\n",
      "us | 4.69 | 4.51 | 4.64 | 4.38 | 4.60\n",
      "ca | 3.70 | 3.45 | 3.53 | 3.27 | 3.36\n",
      "ru | 2.97 | 2.38 | 2.34 | 2.47 | 2.47\n",
      "mean | 2.89 | 2.68 | 2.73 | 2.63 | 2.67\n",
      "standard mean | 1.92 | 1.73 | 1.72 | 1.72 | 1.73\n",
      "seen mean | 2.45 | 2.18 | 2.21 | 2.14 | 2.17\n",
      "unseen mean | 3.13 | 2.92 | 2.99 | 2.86 | 2.91\n",
      "worst | 4.69 | 4.51 | 4.64 | 4.38 | 4.60\n",
      "3-worst mean. | 4.37 | 4.27 | 4.42 | 4.17 | 4.24\n"
     ]
    }
   ],
   "source": [
    "# print the avg. WERs and the means (overall and per class) as a markdown table\n",
    "headers = [\"Accent / Dialect\"] + experiments\n",
    "print((\" | \").join(headers))\n",
    "print(f\"|{'---:|'*len(headers)}\")\n",
    "\n",
    "# print avg. WERs\n",
    "for i in range(len(accents)):\n",
    "    row = [accents[i]] + [f\"{avg_wers[i,j]*100:.2f}\" for j in range(len(experiments))]\n",
    "    print((\" | \").join(row))\n",
    "\n",
    "# print overall means\n",
    "row = [\"mean\"] + [f\"{np.mean(avg_wers[:,i])*100:.2f}\" for i in range(len(experiments))]\n",
    "print((\" | \").join(row))\n",
    "\n",
    "# print class means\n",
    "for key, value in class_means.items():\n",
    "    row = [f\"{key} mean\"] + [f\"{value[i]*100:.2f}\" for i in range(len(experiments))]\n",
    "    print((\" | \").join(row))\n",
    "\n",
    "# print worst avg. WER of each experiment\n",
    "row = [\"worst\"] + [f\"{v*100:.2f}\" for v in np.max(avg_wers, axis=0)]\n",
    "print((\" | \").join(row))\n",
    "\n",
    "# print the avg. of the three worst avg. WERs of each experiment\n",
    "row = [\"3-worst mean.\"] + [f\"{np.mean(np.sort(avg_wers, axis=0)[-3:,i])*100:.2f}\" for i in range(len(experiments))]\n",
    "print((\" | \").join(row))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accent / Dialect | Fine-tuned | b3 | b7 | b11 | b15\n",
    "|---:|---:|---:|---:|---:|---:|\n",
    "at | 1.80 | 1.61 | 1.64 | 1.57 | 1.60\n",
    "gb | 4.11 | 4.03 | 4.44 | 4.03 | 4.03\n",
    "it | 1.40 | 1.34 | 1.33 | 1.29 | 1.30\n",
    "de_al | 1.16 | 1.05 | 1.16 | 1.07 | 1.14\n",
    "fr | 2.68 | 2.32 | 2.29 | 2.28 | 2.32\n",
    "de_ni | 4.31 | 4.27 | 4.17 | 4.09 | 4.08\n",
    "ch | 3.11 | 2.76 | 2.78 | 2.71 | 2.74\n",
    "de | 1.92 | 1.73 | 1.72 | 1.72 | 1.73\n",
    "us | 4.69 | 4.51 | 4.64 | 4.38 | 4.60\n",
    "ca | 3.70 | 3.45 | 3.53 | 3.27 | 3.36\n",
    "ru | 2.97 | 2.38 | 2.34 | 2.47 | 2.47\n",
    "mean | 2.89 | 2.68 | 2.73 | 2.63 | 2.67\n",
    "standard mean | 1.92 | 1.73 | 1.72 | 1.72 | 1.73\n",
    "seen mean | 2.45 | 2.18 | 2.21 | 2.14 | 2.17\n",
    "unseen mean | 3.13 | 2.92 | 2.99 | 2.86 | 2.91\n",
    "worst | 4.69 | 4.51 | 4.64 | 4.38 | 4.60\n",
    "3-worst mean. | 4.37 | 4.27 | 4.42 | 4.17 | 4.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment folders:\n",
      "\n",
      "- Fine-tuned: training `logs/asr/train/version_12`, evaluation `../../logs/de/asr/evaluate/version_4`\n",
      "- b3: training `logs/ensemble/train/binary/b3/DAT/version_3`, evaluation `../../logs/de/asr/evaluate/version_10`\n",
      "- b7: training `logs/ensemble/train/binary/b7/DAT/version_2`, evaluation `../../logs/de/asr/evaluate/version_11`\n",
      "- b11: training `logs/ensemble/train/binary/b11/DAT/version_2`, evaluation `../../logs/de/asr/evaluate/version_12`\n",
      "- b15: training `logs/ensemble/train/binary/b15/DAT/version_3`, evaluation `../../logs/de/asr/evaluate/version_13`\n"
     ]
    }
   ],
   "source": [
    "# print the experiment folders of each experiment (both train and eval folders)\n",
    "print(\"Experiment folders:\\n\")\n",
    "for exp, folder in folders.items():\n",
    "    eval_folder = os.path.join(exp_dir, folder)\n",
    "    eval_config = OmegaConf.load(os.path.join(eval_folder, \"hparams.yaml\"))\n",
    "    train_folder = f'../{eval_config.asr.ckpt.replace(\"/checkpoints/last.ckpt\", \"\")}'\n",
    "    print(f\"- {exp}: training `{train_folder[3:]}`, evaluation `{eval_folder[3:]}`\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bac90b33b2e8bf5368ff2c0ee0f6c7fcb3410fada8b1fda9f71f846ace4b0b44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
