{"test_de_ni.txt": {"avg_wer": 0.048567870485678705, "n_words": 6424}, "test_ch.txt": {"avg_wer": 0.03728932310926005, "n_words": 25691}, "test_de_al.txt": {"avg_wer": 0.015303825956489122, "n_words": 6665}, "test_it.txt": {"avg_wer": 0.03106060606060606, "n_words": 9240}, "test_fr.txt": {"avg_wer": 0.036748229810881064, "n_words": 11157}, "test_de.txt": {"avg_wer": 0.023947691050265632, "n_words": 318110}, "test_ru.txt": {"avg_wer": 0.044052287581699344, "n_words": 7650}, "test_us.txt": {"avg_wer": 0.07288503253796096, "n_words": 2305}, "test_gb.txt": {"avg_wer": 0.05967741935483871, "n_words": 1240}, "test_at.txt": {"avg_wer": 0.024631647179078058, "n_words": 40111}, "test_ca.txt": {"avg_wer": 0.05598621877691645, "n_words": 1161}}