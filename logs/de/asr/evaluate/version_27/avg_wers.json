{"test_de_ni.txt": {"avg_wer": 0.04234122042341221, "n_words": 6424}, "test_ch.txt": {"avg_wer": 0.02744151648437196, "n_words": 25691}, "test_de_al.txt": {"avg_wer": 0.011102775693923482, "n_words": 6665}, "test_it.txt": {"avg_wer": 0.013528138528138528, "n_words": 9240}, "test_fr.txt": {"avg_wer": 0.0225867168593708, "n_words": 11157}, "test_de.txt": {"avg_wer": 0.017333626732891138, "n_words": 318110}, "test_ru.txt": {"avg_wer": 0.024967320261437907, "n_words": 7650}, "test_us.txt": {"avg_wer": 0.04338394793926247, "n_words": 2305}, "test_gb.txt": {"avg_wer": 0.03790322580645161, "n_words": 1240}, "test_at.txt": {"avg_wer": 0.016030515319987036, "n_words": 40111}, "test_ca.txt": {"avg_wer": 0.034453057708871665, "n_words": 1161}}